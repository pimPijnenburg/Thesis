{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>red_channel</th>\n",
       "      <th>green_channel</th>\n",
       "      <th>blue_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[108, 107, 114, 126, 115, 110, 117, 125, 127, ...</td>\n",
       "      <td>[92, 90, 97, 109, 99, 97, 102, 109, 111, 98, 9...</td>\n",
       "      <td>[72, 72, 76, 85, 77, 75, 80, 86, 88, 79, 80, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[44, 50, 50, 53, 43, 37, 39, 40, 43, 49, 53, 5...</td>\n",
       "      <td>[52, 59, 61, 66, 55, 48, 47, 41, 43, 49, 57, 5...</td>\n",
       "      <td>[44, 50, 48, 51, 43, 40, 43, 48, 54, 61, 60, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[40, 41, 40, 46, 51, 48, 47, 48, 39, 30, 38, 4...</td>\n",
       "      <td>[32, 33, 34, 40, 44, 42, 42, 42, 33, 25, 32, 3...</td>\n",
       "      <td>[20, 21, 23, 28, 32, 31, 30, 30, 23, 15, 19, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[139, 144, 154, 154, 155, 154, 151, 146, 145, ...</td>\n",
       "      <td>[105, 107, 115, 116, 117, 117, 115, 113, 113, ...</td>\n",
       "      <td>[86, 86, 92, 93, 94, 94, 94, 93, 92, 89, 87, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[40, 32, 57, 52, 37, 38, 43, 33, 19, 24, 20, 1...</td>\n",
       "      <td>[39, 33, 56, 53, 37, 38, 42, 33, 19, 21, 18, 1...</td>\n",
       "      <td>[37, 30, 52, 50, 35, 36, 40, 31, 17, 19, 15, 9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                        red_channel  \\\n",
       "0      3  [108, 107, 114, 126, 115, 110, 117, 125, 127, ...   \n",
       "1      3  [44, 50, 50, 53, 43, 37, 39, 40, 43, 49, 53, 5...   \n",
       "2      3  [40, 41, 40, 46, 51, 48, 47, 48, 39, 30, 38, 4...   \n",
       "3      3  [139, 144, 154, 154, 155, 154, 151, 146, 145, ...   \n",
       "4      3  [40, 32, 57, 52, 37, 38, 43, 33, 19, 24, 20, 1...   \n",
       "\n",
       "                                       green_channel  \\\n",
       "0  [92, 90, 97, 109, 99, 97, 102, 109, 111, 98, 9...   \n",
       "1  [52, 59, 61, 66, 55, 48, 47, 41, 43, 49, 57, 5...   \n",
       "2  [32, 33, 34, 40, 44, 42, 42, 42, 33, 25, 32, 3...   \n",
       "3  [105, 107, 115, 116, 117, 117, 115, 113, 113, ...   \n",
       "4  [39, 33, 56, 53, 37, 38, 42, 33, 19, 21, 18, 1...   \n",
       "\n",
       "                                        blue_channel  \n",
       "0  [72, 72, 76, 85, 77, 75, 80, 86, 88, 79, 80, 8...  \n",
       "1  [44, 50, 48, 51, 43, 40, 43, 48, 54, 61, 60, 4...  \n",
       "2  [20, 21, 23, 28, 32, 31, 30, 30, 23, 15, 19, 2...  \n",
       "3  [86, 86, 92, 93, 94, 94, 94, 93, 92, 89, 87, 8...  \n",
       "4  [37, 30, 52, 50, 35, 36, 40, 31, 17, 19, 15, 9...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CLASS MAPPING --- \n",
      "{'Cloud': 0, 'Dust': 1, 'Haze': 2, 'Land': 3, 'Seaside': 4, 'Smoke': 5}\n",
      "\n",
      "\n",
      "--- DF SHAPE BEFORE AUGMENTATION --- \n",
      "(6225, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "class_mapping = str({'Cloud': 0, 'Dust': 1, 'Haze': 2, 'Land': 3, 'Seaside': 4, 'Smoke': 5})\n",
    "\n",
    "df = pd.read_parquet('/Users/pimpijnenburg/Desktop/Thesis/USTC_SmokeRS_dataset/data/created_data/smoke_data/smoke_data.parquet')\n",
    "display(df.head())\n",
    "print(f'\\n--- CLASS MAPPING --- \\n{class_mapping}\\n\\n')\n",
    "print(f'--- DF SHAPE BEFORE AUGMENTATION --- \\n{df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(df):\n",
    "    augmented_data = []\n",
    "    for _, row in df.iterrows():\n",
    "        original_image = np.stack([row['red_channel'], row['green_channel'], row['blue_channel']], axis=-1)\n",
    "        original_image = original_image.reshape((256, 256, 3))\n",
    "        \n",
    "        # Original image\n",
    "        augmented_data.append({\n",
    "            'red_channel': original_image[:,:,0].flatten(),\n",
    "            'green_channel': original_image[:,:,1].flatten(),\n",
    "            'blue_channel': original_image[:,:,2].flatten(),\n",
    "            'class': row['class']\n",
    "        })\n",
    "        \n",
    "        # Mirrored image\n",
    "        mirrored = np.fliplr(original_image)\n",
    "        augmented_data.append({\n",
    "            'red_channel': mirrored[:,:,0].flatten(),\n",
    "            'green_channel': mirrored[:,:,1].flatten(),\n",
    "            'blue_channel': mirrored[:,:,2].flatten(),\n",
    "            'class': row['class']\n",
    "        })\n",
    "        \n",
    "        # Rotations of mirrored image (90, 180, 270 degrees)\n",
    "        for k in [1, 2, 3]:  # 90, 180, 270 degrees\n",
    "            rotated = np.rot90(mirrored, k=k)\n",
    "            augmented_data.append({\n",
    "                'red_channel': rotated[:,:,0].flatten(),\n",
    "                'green_channel': rotated[:,:,1].flatten(),\n",
    "                'blue_channel': rotated[:,:,2].flatten(),\n",
    "                'class': row['class']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DF SHAPE AFTER AUGMENTATION --- \n",
      "(31125, 4)\n"
     ]
    }
   ],
   "source": [
    "augmented_df = augment_data(df)\n",
    "print(f'\\n--- DF SHAPE AFTER AUGMENTATION --- \\n{augmented_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full augmented dataframe size utilized.\n",
      "Dataframes' sizes add up to total augmented df size.\n",
      "No index overlap detected.\n",
      "\n",
      "--- TRAIN - VAL - TEST SIZES ---\n",
      "Train size: 24900\n",
      "Validation size: 3112\n",
      "Test size: 3113\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "total_size = augmented_df.shape[0]\n",
    "train_size = int(total_size * 0.8)\n",
    "val_size = (total_size - train_size) // 2\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Verify that all samples are accounted for \n",
    "assert train_size + val_size + test_size == total_size\n",
    "print('Full augmented dataframe size utilized.') \n",
    "\n",
    "X = augmented_df[['red_channel','green_channel','blue_channel']]\n",
    "y = augmented_df['class']\n",
    "\n",
    "# First split: Creating X_train\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, train_size=train_size, \n",
    "                                                            shuffle=True, stratify=y, random_state=1)\n",
    "\n",
    "# Second split: create X_val and X_test\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, train_size=val_size, \n",
    "                                                shuffle=True, stratify=y_val_test, random_state=1)\n",
    "\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "val_df = pd.concat([X_val, y_val], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Assert that the DF's shapes add up\n",
    "assert train_df.shape[0] + val_df.shape[0] + test_df.shape[0] == augmented_df.shape[0]\n",
    "print('Dataframes\\' sizes add up to total augmented df size.')\n",
    "\n",
    "# Assert no overlap between train, val and test set\n",
    "train_idx = set(train_df.index)\n",
    "val_idx = set(val_df.index)\n",
    "test_idx = set(test_df.index)\n",
    "\n",
    "assert len(train_idx.intersection(val_idx)) == 0\n",
    "assert len(train_idx.intersection(test_idx)) == 0\n",
    "assert len(val_idx.intersection(test_idx)) == 0\n",
    "\n",
    "# Assert that all augmented indices are accounted for\n",
    "all_split_indices = train_idx.union(val_idx).union(test_idx)\n",
    "assert len(all_split_indices) == augmented_df.shape[0]\n",
    "\n",
    "print(\"No index overlap detected.\")\n",
    "print()\n",
    "print('--- TRAIN - VAL - TEST SIZES ---')\n",
    "print(f'Train size: {train_df.shape[0]}')\n",
    "print(f'Validation size: {val_df.shape[0]}')\n",
    "print(f'Test size: {test_df.shape[0]}')\n",
    "\n",
    "\n",
    "path = '/Users/pimpijnenburg/Desktop/Thesis/USTC_SmokeRS_dataset/data/created_data/train_val_test_split'\n",
    "\n",
    "train_df.to_parquet(os.path.join(path, 'train.parquet'))\n",
    "val_df.to_parquet(os.path.join(path, 'val.parquet'))\n",
    "test_df.to_parquet(os.path.join(path, 'test.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
