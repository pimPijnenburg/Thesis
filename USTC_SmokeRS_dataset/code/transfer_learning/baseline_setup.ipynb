{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory limit set to 12GB\n"
     ]
    }
   ],
   "source": [
    "from tl_tools import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12288)]\n",
    "        )\n",
    "        print(\"GPU memory limit set to 12GB\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error setting GPU memory limit: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision policy set to: mixed_float16\n",
      "\n",
      "Found 4980 images belonging to 6 classes.\n",
      "Found 1245 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "setup_mixed_precision()\n",
    "train_dir = '/Users/pimpijnenburg/Desktop/Thesis/USTC_SmokeRS_dataset/data/USTC_SmokeRS/processed/train'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip=True ,vertical_flip=True)\n",
    "train =train_datagen.flow_from_directory(train_dir, color_mode= 'rgb', batch_size = 16, shuffle= True, seed = 1, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the training data: 312\n",
      "Batch size of a single batch 16\n",
      "Number of samples in the training dataset 4980\n",
      "\n",
      "Number of training data batches with val split of 0.3: 219\n",
      "Number of validation data batches: 93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 16:00:07.562120: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-10-20 16:00:07.562150: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-10-20 16:00:07.562155: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-10-20 16:00:07.562169: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-20 16:00:07.562179: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of image training set: (3504, 256, 256, 3)\n",
      "Shape of image validation set: (1476, 256, 256, 3)\n",
      "\n",
      "Shape of label training set: (3504, 6)\n",
      "Shape of label validation set: (1476, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val = train_val_split(train, val_split= 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def create_resnet34_like_model(input_shape=(256, 256, 3), num_classes=6):\n",
    "    # Start with the ResNet50V2 model, but without the top layers\n",
    "    base_model = tf.keras.applications.ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Get the output of the second residual block (before the third block)\n",
    "    x = base_model.get_layer('conv3_block3_out').output\n",
    "    \n",
    "    # Add the final stages of ResNet34\n",
    "    x = layers.Conv2D(512, 3, strides=2, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # Add 3 residual blocks (ResNet34 has 3 blocks in its final stage)\n",
    "    for i in range(3):\n",
    "        shortcut = x\n",
    "        x = layers.Conv2D(512, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.Conv2D(512, 3, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Add()([shortcut, x])\n",
    "        x = layers.Activation('relu')(x)\n",
    "    \n",
    "    # Global average pooling\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Custom output layers\n",
    "    # FC 1\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # FC2\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    # Create the model\n",
    "    model = Model(inputs=base_model.input, outputs=outputs, name='ResNet34_like_with_custom_output')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "resnet34_like = create_resnet34_like_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "resnet34_like.compile(optimizer=Adam(learning_rate = 0.01),\n",
    "                     loss='categorical_crossentropy', \n",
    "                     metrics=['accuracy', 'F1Score'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15,restore_best_weights=True, start_from_epoch=50)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_freq = 10 * 110\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_dir = '/Users/pimpijnenburg/Desktop/Thesis/USTC_SmokeRS_dataset/code/transfer_learning/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, 'model_epoch_{epoch:03d}.keras'),\n",
    "    save_weights_only=False, \n",
    "    save_best_only=False,     \n",
    "    save_freq= save_freq, #saves after every 10 * 110 batches per epoch (10 epochs), experienced memory issues\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "#history =  resnet34_like.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, verbose=1, \n",
    "#                             callbacks= [early_stopping, reduce_lr, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuing from checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate: 0.001999999862164259\n"
     ]
    }
   ],
   "source": [
    "latest_checkpoint = '/Users/pimpijnenburg/Desktop/Thesis/USTC_SmokeRS_dataset/code/transfer_learning/checkpoints/model_epoch_040.keras'\n",
    "resnet34_epoch40 = tf.keras.models.load_model(latest_checkpoint)\n",
    "epoch_40_lr = float(tf.keras.backend.get_value(resnet34_epoch40.optimizer.learning_rate))\n",
    "print(f'Current learning rate: {epoch_40_lr}')\n",
    "\n",
    "resnet34_epoch40.compile(\n",
    "    optimizer = Adam(learning_rate= epoch_40_lr),\n",
    "    loss = 'categorical_crossentropy', \n",
    "    metrics = ['accuracy','F1Score']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = resnet34_epoch40.fit(X_train, y_train, validation_data= (X_val, y_val), epochs = 100, initial_epoch= 40, \n",
    "#                               callbacks = [checkpoint_callback, reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current learning rate: 0.0003999999607913196\n"
     ]
    }
   ],
   "source": [
    "latest_checkpoint = '/Users/pimpijnenburg/Desktop/Thesis/USTC_SmokeRS_dataset/code/transfer_learning/checkpoints/model_epoch_080.keras'\n",
    "resnet34_epoch80= tf.keras.models.load_model(latest_checkpoint)\n",
    "epoch_80_lr = float(tf.keras.backend.get_value(resnet34_epoch80.optimizer.learning_rate))\n",
    "print(f'Current learning rate: {epoch_80_lr}')\n",
    "\n",
    "resnet34_epoch80.compile(\n",
    "    optimizer = Adam(learning_rate= epoch_80_lr),\n",
    "    loss = 'categorical_crossentropy', \n",
    "    metrics = ['accuracy','F1Score']\n",
    ")\n",
    "\n",
    "early_stopping_e80 = EarlyStopping(monitor='val_loss', patience=11,restore_best_weights=True, start_from_epoch=50)\n",
    "reduce_lr_e80 = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=8, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-20 16:00:15.442106: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 965ms/step - F1Score: 0.9287 - accuracy: 0.9310 - loss: 0.2031 - val_F1Score: 0.8676 - val_accuracy: 0.8699 - val_loss: 0.3786 - learning_rate: 4.0000e-04\n",
      "Epoch 82/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 905ms/step - F1Score: 0.9269 - accuracy: 0.9282 - loss: 0.2142 - val_F1Score: 0.8709 - val_accuracy: 0.8733 - val_loss: 0.3614 - learning_rate: 4.0000e-04\n",
      "Epoch 83/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 896ms/step - F1Score: 0.9387 - accuracy: 0.9395 - loss: 0.1830 - val_F1Score: 0.8703 - val_accuracy: 0.8733 - val_loss: 0.3796 - learning_rate: 4.0000e-04\n",
      "Epoch 84/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 901ms/step - F1Score: 0.9325 - accuracy: 0.9332 - loss: 0.1931 - val_F1Score: 0.8680 - val_accuracy: 0.8699 - val_loss: 0.3671 - learning_rate: 4.0000e-04\n",
      "Epoch 85/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 900ms/step - F1Score: 0.9377 - accuracy: 0.9386 - loss: 0.1796 - val_F1Score: 0.8684 - val_accuracy: 0.8706 - val_loss: 0.3856 - learning_rate: 4.0000e-04\n",
      "Epoch 86/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 901ms/step - F1Score: 0.9473 - accuracy: 0.9480 - loss: 0.1862 - val_F1Score: 0.8766 - val_accuracy: 0.8780 - val_loss: 0.3788 - learning_rate: 4.0000e-04\n",
      "Epoch 87/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 899ms/step - F1Score: 0.9581 - accuracy: 0.9585 - loss: 0.1343 - val_F1Score: 0.8825 - val_accuracy: 0.8841 - val_loss: 0.3550 - learning_rate: 4.0000e-04\n",
      "Epoch 88/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 901ms/step - F1Score: 0.9432 - accuracy: 0.9449 - loss: 0.1586 - val_F1Score: 0.8575 - val_accuracy: 0.8591 - val_loss: 0.4163 - learning_rate: 4.0000e-04\n",
      "Epoch 89/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 897ms/step - F1Score: 0.9398 - accuracy: 0.9398 - loss: 0.1862 - val_F1Score: 0.8652 - val_accuracy: 0.8665 - val_loss: 0.3827 - learning_rate: 4.0000e-04\n",
      "Epoch 90/120\n",
      "\u001b[1m109/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 847ms/step - F1Score: 0.9440 - accuracy: 0.9448 - loss: 0.1630\n",
      "Epoch 90: saving model to /Users/pimpijnenburg/Desktop/Thesis/USTC_SmokeRS_dataset/code/transfer_learning/checkpoints/model_epoch_090.keras\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 912ms/step - F1Score: 0.9440 - accuracy: 0.9448 - loss: 0.1629 - val_F1Score: 0.8747 - val_accuracy: 0.8767 - val_loss: 0.3821 - learning_rate: 4.0000e-04\n",
      "Epoch 91/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 901ms/step - F1Score: 0.9506 - accuracy: 0.9519 - loss: 0.1559 - val_F1Score: 0.8675 - val_accuracy: 0.8699 - val_loss: 0.4002 - learning_rate: 4.0000e-04\n",
      "Epoch 92/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 902ms/step - F1Score: 0.9384 - accuracy: 0.9406 - loss: 0.1775 - val_F1Score: 0.8521 - val_accuracy: 0.8543 - val_loss: 0.4858 - learning_rate: 4.0000e-04\n",
      "Epoch 93/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 897ms/step - F1Score: 0.9500 - accuracy: 0.9502 - loss: 0.1515 - val_F1Score: 0.8688 - val_accuracy: 0.8699 - val_loss: 0.4214 - learning_rate: 4.0000e-04\n",
      "Epoch 94/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 897ms/step - F1Score: 0.9442 - accuracy: 0.9463 - loss: 0.1627 - val_F1Score: 0.8770 - val_accuracy: 0.8780 - val_loss: 0.4260 - learning_rate: 4.0000e-04\n",
      "Epoch 95/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 896ms/step - F1Score: 0.9476 - accuracy: 0.9486 - loss: 0.1602 - val_F1Score: 0.8741 - val_accuracy: 0.8760 - val_loss: 0.3941 - learning_rate: 4.0000e-04\n",
      "Epoch 96/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 896ms/step - F1Score: 0.9494 - accuracy: 0.9500 - loss: 0.1480 - val_F1Score: 0.8800 - val_accuracy: 0.8814 - val_loss: 0.3763 - learning_rate: 8.0000e-05\n",
      "Epoch 97/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 899ms/step - F1Score: 0.9524 - accuracy: 0.9531 - loss: 0.1358 - val_F1Score: 0.8788 - val_accuracy: 0.8801 - val_loss: 0.3820 - learning_rate: 8.0000e-05\n",
      "Epoch 98/120\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 895ms/step - F1Score: 0.9578 - accuracy: 0.9582 - loss: 0.1386 - val_F1Score: 0.8735 - val_accuracy: 0.8747 - val_loss: 0.4098 - learning_rate: 8.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history = resnet34_epoch80.fit(X_train, y_train, validation_data= (X_val, y_val), epochs = 120, initial_epoch= 80, \n",
    "                               callbacks = [checkpoint_callback, reduce_lr_e80, early_stopping_e80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34_epoch80.save('resnet34v2.keras') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
